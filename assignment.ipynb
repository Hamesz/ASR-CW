{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR Assignment 2020-21\n",
    "\n",
    "This notebook has been provided as a template to get you started on the assignment.  Feel free to use it for your development, or do your development directly in Python.\n",
    "\n",
    "You can find a full description of the assignment [here](http://www.inf.ed.ac.uk/teaching/courses/asr/2020-21/coursework.pdf).\n",
    "\n",
    "You are provided with two Python modules `observation_model.py` and `wer.py`.  The first was described in [Lab 3](https://github.com/Ore-an/asr_labs/blob/master/asr_lab3_4.ipynb).  The second can be used to compute the number of substitution, deletion and insertion errors between ASR output and a reference text.\n",
    "\n",
    "It can be used as follows:\n",
    "\n",
    "```python\n",
    "import wer\n",
    "\n",
    "my_refence = 'A B C'\n",
    "my_output = 'A C C D'\n",
    "\n",
    "wer.compute_alignment_errors(my_reference, my_output)\n",
    "```\n",
    "\n",
    "This produces a tuple $(s,d,i)$ giving counts of substitution,\n",
    "deletion and insertion errors respectively - in this example (1, 0, 1).  The function accepts either two strings, as in the example above, or two lists.  Matching is case sensitive.\n",
    "\n",
    "## Template code\n",
    "\n",
    "Assuming that you have already made a function to generate an WFST, `create_wfst()` and a decoder class, `MyViterbiDecoder`, you can perform recognition on all the audio files as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openfst_python as fst\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image\n",
    "from helper_functions import *\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, word_table = generate_word_sequence_recognition_wfst(3, 'lexicon.txt',original=False)\n",
    "# print (f'word table :{list(word_table)}')\n",
    "# f.draw('tmp.dot', portrait=True)\n",
    "# check_call(['dot','-Tpng','-Gdpi=300','tmp.dot','-o','tmp.png'])\n",
    "# Image(filename='tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logger is used\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "log = logging.getLogger('root')\n",
    "FORMAT = \"%(message)s\"\n",
    "logging.basicConfig(format=FORMAT)\n",
    "log.setLevel(logging.INFO)\n",
    "log.warning('logger is used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import observation_model\n",
    "import math\n",
    "\n",
    "class MyViterbiDecoder:\n",
    "    \n",
    "    NLL_ZERO = 1e10  # define a constant representing -log(0).  This is really infinite, but approximate\n",
    "                     # it here with a very large number\n",
    "    \n",
    "    def __init__(self, f, audio_file_name, word_table):\n",
    "        \"\"\"Set up the decoder class with an audio file and WFST f\n",
    "        \"\"\"\n",
    "        self.om = observation_model.ObservationModel()\n",
    "        self.f = f\n",
    "        self.word_table = word_table\n",
    "        self.forward_computations = 0\n",
    "        \n",
    "        if audio_file_name:\n",
    "            self.om.load_audio(audio_file_name)\n",
    "        else:\n",
    "            self.om.load_dummy_audio()\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "\n",
    "        \n",
    "    def initialise_decoding(self):\n",
    "        \"\"\"set up the values for V_j(0) (as negative log-likelihoods)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.V = []   # stores likelihood along best path reaching state j\n",
    "        self.B = []   # stores identity of best previous state reaching state j\n",
    "        self.W = []   # stores output labels sequence along arc reaching j - this removes need for \n",
    "                      # extra code to read the output sequence along the best path\n",
    "        \n",
    "        for t in range(self.om.observation_length()+1):\n",
    "            self.V.append([self.NLL_ZERO]*self.f.num_states())\n",
    "            self.B.append([-1]*self.f.num_states())\n",
    "            self.W.append([[] for i in range(self.f.num_states())])  #  multiplying the empty list doesn't make multiple\n",
    "        \n",
    "        # The above code means that self.V[t][j] for t = 0, ... T gives the Viterbi cost\n",
    "        # of state j, time t (in negative log-likelihood form)\n",
    "        # Initialising the costs to NLL_ZERO effectively means zero probability    \n",
    "        \n",
    "        # give the WFST start state a probability of 1.0   (NLL = 0.0)\n",
    "        self.V[0][self.f.start()] = 0.0\n",
    "        \n",
    "        # some WFSTs might have arcs with epsilon on the input (you might have already created \n",
    "        # examples of these in earlier labs) these correspond to non-emitting states, \n",
    "        # which means that we need to process them without stepping forward in time.  \n",
    "        # Don't worry too much about this!  \n",
    "        self.traverse_epsilon_arcs(0)        \n",
    "        \n",
    "    def traverse_epsilon_arcs(self, t):\n",
    "        \"\"\"Traverse arcs with <eps> on the input at time t\n",
    "        \n",
    "        These correspond to transitions that don't emit an observation\n",
    "        \n",
    "        We've implemented this function for you as it's slightly trickier than\n",
    "        the normal case.  You might like to look at it to see what's going on, but\n",
    "        don't worry if you can't fully follow it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        states_to_traverse = list(self.f.states()) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)   \n",
    "        \n",
    "            # don't bother traversing states which have zero probability\n",
    "            if self.V[t][i] == self.NLL_ZERO:\n",
    "                    continue\n",
    "        \n",
    "            for arc in self.f.arcs(i):\n",
    "                \n",
    "                if arc.ilabel == 0:     # if <eps> transition\n",
    "                  \n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                \n",
    "                    if self.V[t][j] > self.V[t][i] + float(arc.weight):\n",
    "                        \n",
    "                        # this means we've found a lower-cost path to\n",
    "                        # state j at time t.  We might need to add it\n",
    "                        # back to the processing queue.\n",
    "                        self.V[t][j] = self.V[t][i] + float(arc.weight)\n",
    "                        \n",
    "                        # save backtrace information.  In the case of an epsilon transition, \n",
    "                        # we save the identity of the best state at t-1.  This means we may not\n",
    "                        # be able to fully recover the best path, but to do otherwise would\n",
    "                        # require a more complicated way of storing backtrace information\n",
    "                        self.B[t][j] = self.B[t][i] \n",
    "                        \n",
    "                        # and save the output labels encountered - this is a list, because\n",
    "                        # there could be multiple output labels (in the case of <eps> arcs)\n",
    "                        if arc.olabel != 0:\n",
    "                            self.W[t][j] = self.W[t][i] + [arc.olabel]\n",
    "                        else:\n",
    "                            self.W[t][j] = self.W[t][i]\n",
    "                        \n",
    "                        if j not in states_to_traverse:\n",
    "                            states_to_traverse.append(j)\n",
    "\n",
    "    \n",
    "    def forward_step(self, t):\n",
    "          \n",
    "        for i in self.f.states():\n",
    "            \n",
    "            if not self.V[t-1][i] == self.NLL_ZERO:   # no point in propagating states with zero probability\n",
    "                \n",
    "                for arc in self.f.arcs(i):\n",
    "                    \n",
    "                    if arc.ilabel != 0: # <eps> transitions don't emit an observation\n",
    "                        j = arc.nextstate\n",
    "                        tp = float(arc.weight)  # transition prob\n",
    "                        ep = -self.om.log_observation_probability(self.f.input_symbols().find(arc.ilabel), t)  # emission negative log prob\n",
    "                        prob = tp + ep + self.V[t-1][i] # they're logs\n",
    "                        if prob < self.V[t][j]:\n",
    "                            self.V[t][j] = prob\n",
    "                            self.B[t][j] = i\n",
    "                            \n",
    "                            # store the output labels encountered too\n",
    "                            if arc.olabel !=0:\n",
    "                                self.W[t][j] = [arc.olabel]\n",
    "                            else:\n",
    "                                self.W[t][j] = []\n",
    "                                \n",
    "                        # update number of forward computations\n",
    "                        self.forward_computations += 1\n",
    "                            \n",
    "    \n",
    "    def finalise_decoding(self):\n",
    "        \"\"\" this incorporates the probability of terminating at each state\n",
    "        \"\"\"\n",
    "        \n",
    "        for state in self.f.states():\n",
    "            final_weight = float(self.f.final(state))\n",
    "            if self.V[-1][state] != self.NLL_ZERO:\n",
    "                if final_weight == math.inf:\n",
    "                    self.V[-1][state] = self.NLL_ZERO  # effectively says that we can't end in this state\n",
    "                else:\n",
    "                    self.V[-1][state] += final_weight\n",
    "                    \n",
    "        # get a list of all states where there was a path ending with non-zero probability\n",
    "        finished = [x for x in self.V[-1] if x < self.NLL_ZERO]\n",
    "        if not finished:  # if empty\n",
    "            print(\"No path got to the end of the observations.\")\n",
    "        \n",
    "        \n",
    "    def decode(self):\n",
    "        self.initialise_decoding()\n",
    "        t = 1\n",
    "        while t <= self.om.observation_length():\n",
    "            self.forward_step(t)\n",
    "            self.traverse_epsilon_arcs(t)\n",
    "            t += 1\n",
    "        self.finalise_decoding()\n",
    "    \n",
    "    def backtrace(self):\n",
    "        \n",
    "        best_final_state = self.V[-1].index(min(self.V[-1])) # argmin\n",
    "        best_state_sequence = [best_final_state]\n",
    "        best_out_sequence = []\n",
    "        \n",
    "        t = self.om.observation_length()   # ie T\n",
    "        j = best_final_state\n",
    "        \n",
    "        while t >= 0:\n",
    "            i = self.B[t][j]\n",
    "            best_state_sequence.append(i)\n",
    "            best_out_sequence = self.W[t][j] + best_out_sequence  # computer scientists might like\n",
    "                                                                                # to make this more efficient!\n",
    "            log.debug(f\"W[t][j]: {self.W[t][j]}\")\n",
    "            # continue the backtrace at state i, time t-1\n",
    "            j = i  \n",
    "            t-=1\n",
    "            \n",
    "        best_state_sequence.reverse()\n",
    "        \n",
    "        # convert the best output sequence from FST integer labels into strings\n",
    "#         best_out_sequence = ' '.join([ self.f.output_symbols().find(label) for label in best_out_sequence if self.word_table.find(label)])\n",
    "        best_out_sequence_str = []\n",
    "        word_strs = [x[1] for x in list(self.word_table)]\n",
    "        log.debug(f\"word_strs: {word_strs}\")\n",
    "        for label in best_out_sequence:\n",
    "            label_str = self.f.output_symbols().find(label)\n",
    "            log.debug(f\"label_str: {label_str}\")\n",
    "            if (label_str in word_strs):\n",
    "                best_out_sequence_str += [f'{label_str}']\n",
    "        best_out_sequence_str = ' '.join([x for x in best_out_sequence_str])\n",
    "        return (best_state_sequence, best_out_sequence_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import wer\n",
    "import observation_model\n",
    "import openfst_python as fst\n",
    "\n",
    "def read_transcription(wav_file):\n",
    "    \"\"\"\n",
    "    Get the transcription corresponding to wav_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    transcription_file = os.path.splitext(wav_file)[0] + '.txt'\n",
    "    \n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.readline().strip()\n",
    "    \n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder = '/group/teaching/asr/labs/individual_recordings/s1645821'\n",
    "folder = '/group/teaching/asr/labs/recordings'\n",
    "wavs_txt = [os.path.join(folder,x) for x in os.listdir(folder)]\n",
    "wavs = [wav for wav in wavs_txt if ('.wav' in wav)]\n",
    "txts = [wav for wav in wavs_txt if ('.txt' in wav)]\n",
    "# wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_lex = True\n",
    "# f, word_table = generate_word_sequence_recognition_wfst(3, 'lexicon.txt',False, False)\n",
    "# print (f'word table :{list(word_table)}')\n",
    "# f.draw('tmp.dot', portrait=True)\n",
    "# check_call(['dot','-Tpng','-Gdpi=300','tmp.dot','-o','tmp.png'])\n",
    "# Image(filename='tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav_file = wavs[0]\n",
    "# decoder = MyViterbiDecoder(f, wav_file, word_table)\n",
    "# decoder.decode()\n",
    "# (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#                                            # to return the words along the best path\n",
    "# log.debug(f\"State path: {state_path}\\nWords: {words}\")\n",
    "# transcription = read_transcription(wav_file)\n",
    "# log.info(f\"Words: {words}\")\n",
    "# log.info(f'Transcription: {transcription}')\n",
    "# error_counts = wer.compute_alignment_errors(transcription, words) # num_subs, num_del, num_ins\n",
    "# word_count = len(transcription.split())\n",
    "\n",
    "# log.info(f\"Error_counts: {error_counts}, word_count: {word_count}\")     # you'll need to accumulate these to produce an overall Word Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WFTS that uses 0.1 for self trans, and 0.9 for next trans, without different phones for same word\n",
    "WFST_1_9_O = generate_word_sequence_recognition_wfst(3, 'lexicon.txt',True, True)\n",
    "\n",
    "# WFTS that uses 0.1 for self trans, and 0.9 for next trans, with different phones for same word\n",
    "WFST_1_9 = generate_word_sequence_recognition_wfst(3, 'lexicon.txt',False, True)\n",
    "\n",
    "# WFST that doesnt use probs all trans are None but is original\n",
    "WFST_O = generate_word_sequence_recognition_wfst(3, 'lexicon.txt',True, False)\n",
    "\n",
    "# WFST that doesnt use probs all trans are None but is not original\n",
    "WFST = generate_word_sequence_recognition_wfst(3, 'lexicon.txt',False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error_counts = []\n",
    "total_word_counts = []\n",
    "\n",
    "total_average_decoder_times = []\n",
    "total_average_backtrace_times = []\n",
    "\n",
    "total_forward_computations = []\n",
    "\n",
    "different_fs_word_table = [WFST_1_9_O, WFST_1_9, WFST_O, WFST]\n",
    "\n",
    "for f, word_table in different_fs_word_table[:]:\n",
    "    f_error_counts = [0,0,0]\n",
    "    f_word_counts = 0\n",
    "    decoder_times = []\n",
    "    backtrace_times = []\n",
    "    forward_computations = []\n",
    "    # -- Dataframe\n",
    "    \n",
    "    \n",
    "    for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav')[:]:    # replace path if using your own\n",
    "        \n",
    "        decoder = MyViterbiDecoder(f, wav_file, word_table)\n",
    "        \n",
    "        decoder_start_time = time.time()\n",
    "        decoder.decode()\n",
    "        decoder_end_time  = time.time()\n",
    "        (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                           # to return the words along the best path\n",
    "        backtrace_end_time = time.time()\n",
    "        \n",
    "        transcription = read_transcription(wav_file)\n",
    "        error_counts = wer.compute_alignment_errors(transcription, words) #num_subs, num_del, num_ins\n",
    "        word_count = len(transcription.split())\n",
    "        \n",
    "        # add up output\n",
    "        f_word_counts += word_count\n",
    "        f_error_counts[0] += error_counts[0]\n",
    "        f_error_counts[1] += error_counts[1]\n",
    "        f_error_counts[2] += error_counts[2]\n",
    "#         print(error_counts, word_count)     # you'll need to accumulate these to produce an overall Word Error Rate\n",
    "        \n",
    "        # add up times\n",
    "        decoder_time = decoder_end_time - decoder_start_time\n",
    "        backtrace_time = backtrace_end_time - decoder_end_time\n",
    "        \n",
    "        decoder_times.append(decoder_time)\n",
    "        backtrace_times.append(backtrace_time)\n",
    "        \n",
    "        # add up conputations\n",
    "        forward_computations.append(decoder.forward_computations)\n",
    "        \n",
    "        # -- add to DataFrame\n",
    "        wav_name = wav_file.split('\\\\')[-1]\n",
    "        pd_row = []\n",
    "        \n",
    "    total_error_counts.append(f_error_counts)\n",
    "    total_word_counts.append(f_word_counts)\n",
    "    \n",
    "    total_average_decoder_times.append(sum(decoder_times)/len(decoder_times))\n",
    "    total_average_backtrace_times.append(sum(backtrace_times)/len(backtrace_times))\n",
    "    \n",
    "    total_forward_computations.append(sum(forward_computations)/len(forward_computations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['WFST', 'S', 'D', 'I', 'Accuracy','Word Counts', 'Decoder Times', 'Backtrace Times', 'Forward Computations']\n",
    "WFSTs = ['baseline log', 'multi word log', 'None weight original', 'None weight multi word']\n",
    "total_error_counts = np.array(total_error_counts)\n",
    "subs = total_error_counts[:,0]\n",
    "deletions = total_error_counts[:,1]\n",
    "insertions = total_error_counts[:,2]\n",
    "accuracies = ((subs + deletions + insertions)/total_word_counts)*100\n",
    "df = pd.DataFrame((WFSTs, subs, deletions, insertions, accuracies, total_word_counts, total_average_decoder_times, total_average_backtrace_times, total_forward_computations),index=columns).T\n",
    "df.to_excel('wfsts.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0 ----\n",
      "Errors: [ 5  0 17], word count: 21\n",
      "Accuracy for F (0): 104.76190476190477\n",
      "\n",
      "---- 1 ----\n",
      "Errors: [ 3  0 23], word count: 21\n",
      "Accuracy for F (1): 123.80952380952381\n",
      "\n",
      "---- 2 ----\n",
      "Errors: [4 1 4], word count: 21\n",
      "Accuracy for F (2): 42.857142857142854\n",
      "\n",
      "---- 3 ----\n",
      "Errors: [3 1 4], word count: 21\n",
      "Accuracy for F (3): 38.095238095238095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "for idx, (f, word_table) in enumerate(different_fs_word_table[:]):\n",
    "    error = total_error_counts[idx]\n",
    "    word_count = total_word_counts[idx]\n",
    "    \n",
    "    accuracy = (error[0] + error[1] + error[2])/word_count\n",
    "    accuracy = accuracy * 100\n",
    "    \n",
    "    print(f'---- {idx} ----')\n",
    "    print(f\"Errors: {error}, word count: {word_count}\")\n",
    "    print(f\"Accuracy for F ({idx}): {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0 ----\n",
      "Average Decode time: 1.9447619120279949\n",
      "Average backtrace time: 0.0006755193074544271\n",
      "\n",
      "---- 1 ----\n",
      "Average Decode time: 2.135376214981079\n",
      "Average backtrace time: 0.0008070468902587891\n",
      "\n",
      "---- 2 ----\n",
      "Average Decode time: 1.9157028992970784\n",
      "Average backtrace time: 0.0006573994954427084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# speed\n",
    "for idx, (f, word_table) in enumerate(different_fs_word_table[:3]):\n",
    "    decode_time = total_average_decoder_times[idx]\n",
    "    backtrace_time = total_average_backtrace_times[idx]\n",
    "    \n",
    "    print(f'---- {idx} ----')\n",
    "    print(f\"Average Decode time: {decode_time}\")\n",
    "    print(f\"Average backtrace time: {backtrace_time}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0 ----\n",
      "Number of states: 116\n",
      "Number of arcs: 230\n"
     ]
    }
   ],
   "source": [
    "# memory\n",
    "for idx, (f, word_table) in enumerate(different_fs_word_table[:1]):\n",
    "    num_states = f.num_states()\n",
    "    # why 1 + f.num_arcs(s)\n",
    "    num_arcs = sum([f.num_arcs(s) for s in f.states()])\n",
    "    \n",
    "    print(f'---- {idx} ----')\n",
    "    print(f\"Number of states: {num_states}\")\n",
    "    print(f\"Number of arcs: {num_arcs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0 ----\n",
      "Number of forward compuations: [68328, 68328]\n"
     ]
    }
   ],
   "source": [
    "# forward_computations\n",
    "for f, word_table in enumerate(different_fs_word_table[:1]):\n",
    "    forward_computations = total_forward_computations[idx]\n",
    "    \n",
    "    print(f'---- {idx} ----')\n",
    "    print(f\"Number of forward compuations: {forward_computations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68328], [68328], [68328, 68328], [68328, 68328]]\n"
     ]
    }
   ],
   "source": [
    "print(total_forward_computations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
